{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/daviderickson/projects/datasf/data/Police_Department_Incident_Reports__Historical_2003_to_May_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Address', 'X', 'Y', 'Location', 'PdId',\n",
    "       'SF Find Neighborhoods', 'Current Police Districts',\n",
    "       'Current Supervisor Districts', 'Analysis Neighborhoods']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_list = ['Address', 'X', 'Y', 'Location', 'PdId',\n",
    "       'SF Find Neighborhoods', 'Current Police Districts',\n",
    "       'Current Supervisor Districts', 'Analysis Neighborhoods']\n",
    "for col in cols_list:\n",
    "    series = df[col]\n",
    "    series.unique()\n",
    "    print(col, '- unique entries - ', len(series.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns: \n",
    "    series = df[col]\n",
    "    print(len(series.unique()), col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Resolution').count()['IncidntNum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res_dow = df.pivot_table('IncidntNum', index='Resolution', columns='DayOfWeek', aggfunc='count', margins=False)\n",
    "dow_list = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "df_res_dow['total'] = df_res_dow.sum(axis=1)\n",
    "for col in df_res_dow.columns:\n",
    "    df_res_dow[col] = df_res_dow[col] / df_res_dow['total']\n",
    "df_res_dow.drop('total', axis=1, inplace=True)\n",
    "df_res_dow = df_res_dow[dow_list]\n",
    "df_res_dow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_list = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "df_cat_dow = df.pivot_table('IncidntNum', index='Category', columns='DayOfWeek', aggfunc='count', margins=False)\n",
    "\n",
    "df_cat_dow['total'] = df_cat_dow.sum(axis=1)\n",
    "for col in df_cat_dow.columns:\n",
    "    df_cat_dow[col] = df_cat_dow[col] / df_cat_dow['total']\n",
    "df_cat_dow.drop('total', axis=1, inplace=True)\n",
    "df_cat_dow = df_cat_dow[dow_list]\n",
    "df_cat_dow\n",
    "\n",
    "plt.figure(figsize=(5,8))\n",
    "ax = sns.heatmap(df_cat_dow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Category')['Category'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('DayOfWeek')['DayOfWeek'].count().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[df.dtypes == 'object'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df['Resolution'].dropna(axis=0).shape)\n",
    "print(df['Resolution'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def make_Xy_RF(df, ylabel='Resolution'): \n",
    "    df1 = df.dropna(axis=0) #Drop rows w/ NA\n",
    "    y = df1[ylabel]\n",
    "    \n",
    "    drop_cols = [ylabel, 'IncidntNum', 'Location', 'Address', 'Descript', 'Date', 'Time'] \n",
    "        # May also want to drop ':@computed_region_' cols, which have lots of NaNs\n",
    "    drop_cols = set(drop_cols) & set(df1.columns)\n",
    "    df1 = df1.drop(drop_cols, axis=1)\n",
    "    print(df1.columns)\n",
    "    dummies_cols = df1.columns[df1.dtypes == 'object'].to_list()\n",
    "    df1 = pd.get_dummies(df1, columns=dummies_cols)\n",
    "    X = df1.loc[:,:].values\n",
    "    X_cols = df1.loc[:,:].columns\n",
    "    return X, y, X_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_cols = make_Xy_RF(df, ylabel='Resolution')\n",
    "model = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "param_range=[4,5,6,8,10,13,20,30,40,50,60,100]\n",
    "train_scores_vc, test_scores_vc = \\\n",
    "    validation_curve(estimator=model, X=X, y=y, param_name=\"n_estimators\", param_range=param_range, \\\n",
    "                     cv=10, n_jobs=-1, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = np.mean(train_scores_vc, axis=1)\n",
    "train_scores_std = np.std(train_scores_vc, axis=1)\n",
    "test_scores_mean = np.mean(test_scores_vc, axis=1)\n",
    "test_scores_std = np.std(test_scores_vc, axis=1)\n",
    "\n",
    "ax = plt.figure()\n",
    "plt.plot(param_range,train_scores_mean,'o',label=\"Train\")\n",
    "plt.plot(param_range,test_scores_mean,'o',label=\"Test\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Validation Curves\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xscale('log')\n",
    "plt.fill_between(param_range, train_scores_mean+train_scores_std, train_scores_mean-train_scores_std, \n",
    "                facecolor='blue', alpha=0.5)\n",
    "plt.fill_between(param_range, test_scores_mean+test_scores_std, test_scores_mean-test_scores_std, \n",
    "                facecolor='orange', alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_cols = make_Xy_RF(df, ylabel='Category')\n",
    "model = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "param_range=[4,5,6,8,10,13,20,30,40,50,60,100]\n",
    "train_scores_vc, test_scores_vc = \\\n",
    "    validation_curve(estimator=model, X=X, y=y, param_name=\"n_estimators\", param_range=param_range, \\\n",
    "                     cv=10, n_jobs=-1, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = np.mean(train_scores_vc, axis=1)\n",
    "train_scores_std = np.std(train_scores_vc, axis=1)\n",
    "test_scores_mean = np.mean(test_scores_vc, axis=1)\n",
    "test_scores_std = np.std(test_scores_vc, axis=1)\n",
    "\n",
    "ax = plt.figure()\n",
    "plt.plot(param_range,train_scores_mean,'o',label=\"Train\")\n",
    "plt.plot(param_range,test_scores_mean,'o',label=\"Test\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Validation Curves\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xscale('log')\n",
    "plt.fill_between(param_range, train_scores_mean+train_scores_std, train_scores_mean-train_scores_std, \n",
    "                facecolor='blue', alpha=0.5)\n",
    "plt.fill_between(param_range, test_scores_mean+test_scores_std, test_scores_mean-test_scores_std, \n",
    "                facecolor='orange', alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ass = df[df['Category'] == 'WARRANTS']\n",
    "X, y, X_cols = make_Xy_RF(df_ass, ylabel='Resolution')\n",
    "model = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "param_range=[5,10,30,100,300]\n",
    "train_scores_vc, test_scores_vc = \\\n",
    "    validation_curve(estimator=model, X=X, y=y, param_name=\"n_estimators\", param_range=param_range, \\\n",
    "                     cv=10, n_jobs=-1, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = np.mean(train_scores_vc, axis=1)\n",
    "train_scores_std = np.std(train_scores_vc, axis=1)\n",
    "test_scores_mean = np.mean(test_scores_vc, axis=1)\n",
    "test_scores_std = np.std(test_scores_vc, axis=1)\n",
    "\n",
    "ax = plt.figure()\n",
    "plt.plot(param_range,train_scores_mean,'o',label=\"Train\")\n",
    "plt.plot(param_range,test_scores_mean,'o',label=\"Test\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Validation Curves\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xscale('log')\n",
    "plt.fill_between(param_range, train_scores_mean+train_scores_std, train_scores_mean-train_scores_std, \n",
    "                facecolor='blue', alpha=0.5)\n",
    "plt.fill_between(param_range, test_scores_mean+test_scores_std, test_scores_mean-test_scores_std, \n",
    "                facecolor='orange', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "feature_importances_rf = pd.DataFrame(model.feature_importances_, index = X_cols, columns=['importance']).sort_values('importance',ascending=False)\n",
    "feature_importances_rf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF Classifier\n",
    "## Predict Category Given Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = ['Category', 'Descript']\n",
    "df_desc = df[keep_cols].copy()\n",
    "df_desc.dropna()\n",
    "\n",
    "y = df_desc['Category']\n",
    "df_desc.drop('Category', axis=1, inplace=True)\n",
    "\n",
    "print(df_desc.columns)\n",
    "df_desc = pd.get_dummies(df_desc)\n",
    "X = df_desc.loc[:,:].values\n",
    "X_cols = df_desc.loc[:,:].columns\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "param_range=[5,10,30,100,300]\n",
    "train_scores_vc, test_scores_vc = \\\n",
    "    validation_curve(estimator=model, X=X, y=y, param_name=\"n_estimators\", param_range=param_range, \\\n",
    "                     cv=10, n_jobs=-1, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = np.mean(train_scores_vc, axis=1)\n",
    "train_scores_std = np.std(train_scores_vc, axis=1)\n",
    "test_scores_mean = np.mean(test_scores_vc, axis=1)\n",
    "test_scores_std = np.std(test_scores_vc, axis=1)\n",
    "\n",
    "ax = plt.figure()\n",
    "plt.plot(param_range,train_scores_mean,'o',label=\"Train\")\n",
    "plt.plot(param_range,test_scores_mean,'o',label=\"Test\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Validation Curves\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xscale('log')\n",
    "plt.fill_between(param_range, train_scores_mean+train_scores_std, train_scores_mean-train_scores_std, \n",
    "                facecolor='blue', alpha=0.5)\n",
    "plt.fill_between(param_range, test_scores_mean+test_scores_std, test_scores_mean-test_scores_std, \n",
    "                facecolor='orange', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
